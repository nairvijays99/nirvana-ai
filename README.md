Nirvana Ai

Your personal assistant that runs 100% locally

## Prerequsites

- Local Ollama instance
- `llama3.1:8b` model
- `embeddinggemma` embedding model

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

## Phase 2 preview

<image-card alt="Screenshot" src="doc-images/screenshot.png" ></image-card>
